{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data Science Project: Daily News for Stock Market Prediction\n",
    "## Team member: Chien-Ming Huang, Tong Chen, Po Chun Chen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Source: Kaggle \n",
    "https://www.kaggle.com/aaron7sun/stocknews/data\n",
    "#### News Data: \n",
    "Daily top 25 headlines from Reddit WorldNews Channel (/r/worldnews), ranked by reddit users' votes for every date.<br> (Range: 2008-06-08 to 2016-07-01)\n",
    "\n",
    "#### Stock Data: \n",
    "Dow Jones Industrial Average (DJIA).<br> (Range: 2008-08-08 to 2016-07-01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pipeline for Daily News for Stock Market Prediction\n",
    "### Build a binary classfication problem:\n",
    "\"1\" when DJIA Adj Close value rose or stayed as the same <br>\n",
    "\"0\" when DJIA Adj Close value decreased\n",
    "### Task Evaluation:\n",
    "Training Set: Data from 2008-08-08 to 2014-12-31 <br>\n",
    "Test Set: Data from 2015-01-02 to 2016-07-01 <br>\n",
    "split approximately 80% / 20%\n",
    "### Evaluation Metric:\n",
    "Mainly use AUC as the evaluation metric, also include precison, recall, F1-score, support for comparison)\n",
    "### Preprocessing:\n",
    "1. Tokenizes\n",
    "2. Removes stopwords and coverts headlines to lowercase letters\n",
    "3. Stems\n",
    "4. Returns a list of the cleaned text\n",
    "\n",
    "### Bag of Words (N-Gram Model) & TFIDF Intro:\n",
    "Perform Count Vecotrizer & TF-IDF transformer\n",
    "\n",
    "### Feature Selection:\n",
    "1. N-days shifts (1-3)\n",
    "2. Top 3, 10, 25 news\n",
    "\n",
    "### Model Selection:\n",
    "Logistic Regression, Naive Bayes, and Random Forest\n",
    "\n",
    "### Performance Comparison\n",
    "\n",
    "### Other insight: Sentimental Analysis\n",
    "\n",
    "### Other insight: Key Words visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dataframe\n",
    "import pandas as pd\n",
    "from pandas import Series,DataFrame\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "\n",
    "# Data Preprocessing\n",
    "# Make sure conda has nltk pacakge\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# Evaluation Metrics\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc,precision_score, accuracy_score, recall_score, f1_score\n",
    "from scipy import interp\n",
    "\n",
    "# Word Count & TF-IDF\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import GridSearchCV # hyper parameter tuning\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from wordcloud import WordCloud # Need pip install wordcloud first\n",
    "import matplotlib\n",
    "matplotlib.rcParams[\"figure.figsize\"] = \"8, 8\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Label</th>\n",
       "      <th>Top1</th>\n",
       "      <th>Top2</th>\n",
       "      <th>Top3</th>\n",
       "      <th>Top4</th>\n",
       "      <th>Top5</th>\n",
       "      <th>Top6</th>\n",
       "      <th>Top7</th>\n",
       "      <th>Top8</th>\n",
       "      <th>...</th>\n",
       "      <th>Top17</th>\n",
       "      <th>Top18</th>\n",
       "      <th>Top19</th>\n",
       "      <th>Top20</th>\n",
       "      <th>Top21</th>\n",
       "      <th>Top22</th>\n",
       "      <th>Top23</th>\n",
       "      <th>Top24</th>\n",
       "      <th>Top25</th>\n",
       "      <th>Combined25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-08-08</td>\n",
       "      <td>0</td>\n",
       "      <td>b\"Georgia 'downs two Russian warplanes' as cou...</td>\n",
       "      <td>b'BREAKING: Musharraf to be impeached.'</td>\n",
       "      <td>b'Russia Today: Columns of troops roll into So...</td>\n",
       "      <td>b'Russian tanks are moving towards the capital...</td>\n",
       "      <td>b\"Afghan children raped with 'impunity,' U.N. ...</td>\n",
       "      <td>b'150 Russian tanks have entered South Ossetia...</td>\n",
       "      <td>b\"Breaking: Georgia invades South Ossetia, Rus...</td>\n",
       "      <td>b\"The 'enemy combatent' trials are nothing but...</td>\n",
       "      <td>...</td>\n",
       "      <td>b'Al-Qaeda Faces Islamist Backlash'</td>\n",
       "      <td>b'Condoleezza Rice: \"The US would not act to p...</td>\n",
       "      <td>b'This is a busy day:  The European Union has ...</td>\n",
       "      <td>b\"Georgia will withdraw 1,000 soldiers from Ir...</td>\n",
       "      <td>b'Why the Pentagon Thinks Attacking Iran is a ...</td>\n",
       "      <td>b'Caucasus in crisis: Georgia invades South Os...</td>\n",
       "      <td>b'Indian shoe manufactory  - And again in a se...</td>\n",
       "      <td>b'Visitors Suffering from Mental Illnesses Ban...</td>\n",
       "      <td>b\"No Help for Mexico's Kidnapping Surge\"</td>\n",
       "      <td>[ 'b\"Georgia \\'downs two Russian warplanes\\' a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-08-11</td>\n",
       "      <td>1</td>\n",
       "      <td>b'Why wont America and Nato help us? If they w...</td>\n",
       "      <td>b'Bush puts foot down on Georgian conflict'</td>\n",
       "      <td>b\"Jewish Georgian minister: Thanks to Israeli ...</td>\n",
       "      <td>b'Georgian army flees in disarray as Russians ...</td>\n",
       "      <td>b\"Olympic opening ceremony fireworks 'faked'\"</td>\n",
       "      <td>b'What were the Mossad with fraudulent New Zea...</td>\n",
       "      <td>b'Russia angered by Israeli military sale to G...</td>\n",
       "      <td>b'An American citizen living in S.Ossetia blam...</td>\n",
       "      <td>...</td>\n",
       "      <td>b'\"Do not believe TV, neither Russian nor Geor...</td>\n",
       "      <td>b'Riots are still going on in Montreal (Canada...</td>\n",
       "      <td>b'China to overtake US as largest manufacturer'</td>\n",
       "      <td>b'War in South Ossetia [PICS]'</td>\n",
       "      <td>b'Israeli Physicians Group Condemns State Tort...</td>\n",
       "      <td>b' Russia has just beaten the United States ov...</td>\n",
       "      <td>b'Perhaps *the* question about the Georgia - R...</td>\n",
       "      <td>b'Russia is so much better at war'</td>\n",
       "      <td>b\"So this is what it's come to: trading sex fo...</td>\n",
       "      <td>[ \"b'Why wont America and Nato help us? If the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-08-12</td>\n",
       "      <td>0</td>\n",
       "      <td>b'Remember that adorable 9-year-old who sang a...</td>\n",
       "      <td>b\"Russia 'ends Georgia operation'\"</td>\n",
       "      <td>b'\"If we had no sexual harassment we would hav...</td>\n",
       "      <td>b\"Al-Qa'eda is losing support in Iraq because ...</td>\n",
       "      <td>b'Ceasefire in Georgia: Putin Outmaneuvers the...</td>\n",
       "      <td>b'Why Microsoft and Intel tried to kill the XO...</td>\n",
       "      <td>b'Stratfor: The Russo-Georgian War and the Bal...</td>\n",
       "      <td>b\"I'm Trying to Get a Sense of This Whole Geor...</td>\n",
       "      <td>...</td>\n",
       "      <td>b'Why Russias response to Georgia was right'</td>\n",
       "      <td>b'Gorbachev accuses U.S. of making a \"serious ...</td>\n",
       "      <td>b'Russia, Georgia, and NATO: Cold War Two'</td>\n",
       "      <td>b'Remember that adorable 62-year-old who led y...</td>\n",
       "      <td>b'War in Georgia: The Israeli connection'</td>\n",
       "      <td>b'All signs point to the US encouraging Georgi...</td>\n",
       "      <td>b'Christopher King argues that the US and NATO...</td>\n",
       "      <td>b'America: The New Mexico?'</td>\n",
       "      <td>b\"BBC NEWS | Asia-Pacific | Extinction 'by man...</td>\n",
       "      <td>[ \"b'Remember that adorable 9-year-old who san...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-08-13</td>\n",
       "      <td>0</td>\n",
       "      <td>b' U.S. refuses Israel weapons to attack Iran:...</td>\n",
       "      <td>b\"When the president ordered to attack Tskhinv...</td>\n",
       "      <td>b' Israel clears troops who killed Reuters cam...</td>\n",
       "      <td>b'Britain\\'s policy of being tough on drugs is...</td>\n",
       "      <td>b'Body of 14 year old found in trunk; Latest (...</td>\n",
       "      <td>b'China has moved 10 *million* quake survivors...</td>\n",
       "      <td>b\"Bush announces Operation Get All Up In Russi...</td>\n",
       "      <td>b'Russian forces sink Georgian ships '</td>\n",
       "      <td>...</td>\n",
       "      <td>b'US humanitarian missions soon in Georgia - i...</td>\n",
       "      <td>b\"Georgia's DDOS came from US sources\"</td>\n",
       "      <td>b'Russian convoy heads into Georgia, violating...</td>\n",
       "      <td>b'Israeli defence minister: US against strike ...</td>\n",
       "      <td>b'Gorbachev: We Had No Choice'</td>\n",
       "      <td>b'Witness: Russian forces head towards Tbilisi...</td>\n",
       "      <td>b' Quarter of Russians blame U.S. for conflict...</td>\n",
       "      <td>b'Georgian president  says US military will ta...</td>\n",
       "      <td>b'2006: Nobel laureate Aleksander Solzhenitsyn...</td>\n",
       "      <td>[\"b' U.S. refuses Israel weapons to attack Ira...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-08-14</td>\n",
       "      <td>1</td>\n",
       "      <td>b'All the experts admit that we should legalis...</td>\n",
       "      <td>b'War in South Osetia - 89 pictures made by a ...</td>\n",
       "      <td>b'Swedish wrestler Ara Abrahamian throws away ...</td>\n",
       "      <td>b'Russia exaggerated the death toll in South O...</td>\n",
       "      <td>b'Missile That Killed 9 Inside Pakistan May Ha...</td>\n",
       "      <td>b\"Rushdie Condemns Random House's Refusal to P...</td>\n",
       "      <td>b'Poland and US agree to missle defense deal. ...</td>\n",
       "      <td>b'Will the Russians conquer Tblisi? Bet on it,...</td>\n",
       "      <td>...</td>\n",
       "      <td>b\"Georgia confict could set back Russia's US r...</td>\n",
       "      <td>b'War in the Caucasus is as much the product o...</td>\n",
       "      <td>b'\"Non-media\" photos of South Ossetia/Georgia ...</td>\n",
       "      <td>b'Georgian TV reporter shot by Russian sniper ...</td>\n",
       "      <td>b'Saudi Arabia: Mother moves to block child ma...</td>\n",
       "      <td>b'Taliban wages war on humanitarian aid workers'</td>\n",
       "      <td>b'Russia: World  \"can forget about\" Georgia\\'s...</td>\n",
       "      <td>b'Darfur rebels accuse Sudan of mounting major...</td>\n",
       "      <td>b'Philippines : Peace Advocate say Muslims nee...</td>\n",
       "      <td>[\"b'All the experts admit that we should legal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Label                                               Top1  \\\n",
       "0  2008-08-08      0  b\"Georgia 'downs two Russian warplanes' as cou...   \n",
       "1  2008-08-11      1  b'Why wont America and Nato help us? If they w...   \n",
       "2  2008-08-12      0  b'Remember that adorable 9-year-old who sang a...   \n",
       "3  2008-08-13      0  b' U.S. refuses Israel weapons to attack Iran:...   \n",
       "4  2008-08-14      1  b'All the experts admit that we should legalis...   \n",
       "\n",
       "                                                Top2  \\\n",
       "0            b'BREAKING: Musharraf to be impeached.'   \n",
       "1        b'Bush puts foot down on Georgian conflict'   \n",
       "2                 b\"Russia 'ends Georgia operation'\"   \n",
       "3  b\"When the president ordered to attack Tskhinv...   \n",
       "4  b'War in South Osetia - 89 pictures made by a ...   \n",
       "\n",
       "                                                Top3  \\\n",
       "0  b'Russia Today: Columns of troops roll into So...   \n",
       "1  b\"Jewish Georgian minister: Thanks to Israeli ...   \n",
       "2  b'\"If we had no sexual harassment we would hav...   \n",
       "3  b' Israel clears troops who killed Reuters cam...   \n",
       "4  b'Swedish wrestler Ara Abrahamian throws away ...   \n",
       "\n",
       "                                                Top4  \\\n",
       "0  b'Russian tanks are moving towards the capital...   \n",
       "1  b'Georgian army flees in disarray as Russians ...   \n",
       "2  b\"Al-Qa'eda is losing support in Iraq because ...   \n",
       "3  b'Britain\\'s policy of being tough on drugs is...   \n",
       "4  b'Russia exaggerated the death toll in South O...   \n",
       "\n",
       "                                                Top5  \\\n",
       "0  b\"Afghan children raped with 'impunity,' U.N. ...   \n",
       "1      b\"Olympic opening ceremony fireworks 'faked'\"   \n",
       "2  b'Ceasefire in Georgia: Putin Outmaneuvers the...   \n",
       "3  b'Body of 14 year old found in trunk; Latest (...   \n",
       "4  b'Missile That Killed 9 Inside Pakistan May Ha...   \n",
       "\n",
       "                                                Top6  \\\n",
       "0  b'150 Russian tanks have entered South Ossetia...   \n",
       "1  b'What were the Mossad with fraudulent New Zea...   \n",
       "2  b'Why Microsoft and Intel tried to kill the XO...   \n",
       "3  b'China has moved 10 *million* quake survivors...   \n",
       "4  b\"Rushdie Condemns Random House's Refusal to P...   \n",
       "\n",
       "                                                Top7  \\\n",
       "0  b\"Breaking: Georgia invades South Ossetia, Rus...   \n",
       "1  b'Russia angered by Israeli military sale to G...   \n",
       "2  b'Stratfor: The Russo-Georgian War and the Bal...   \n",
       "3  b\"Bush announces Operation Get All Up In Russi...   \n",
       "4  b'Poland and US agree to missle defense deal. ...   \n",
       "\n",
       "                                                Top8  \\\n",
       "0  b\"The 'enemy combatent' trials are nothing but...   \n",
       "1  b'An American citizen living in S.Ossetia blam...   \n",
       "2  b\"I'm Trying to Get a Sense of This Whole Geor...   \n",
       "3             b'Russian forces sink Georgian ships '   \n",
       "4  b'Will the Russians conquer Tblisi? Bet on it,...   \n",
       "\n",
       "                         ...                          \\\n",
       "0                        ...                           \n",
       "1                        ...                           \n",
       "2                        ...                           \n",
       "3                        ...                           \n",
       "4                        ...                           \n",
       "\n",
       "                                               Top17  \\\n",
       "0                b'Al-Qaeda Faces Islamist Backlash'   \n",
       "1  b'\"Do not believe TV, neither Russian nor Geor...   \n",
       "2       b'Why Russias response to Georgia was right'   \n",
       "3  b'US humanitarian missions soon in Georgia - i...   \n",
       "4  b\"Georgia confict could set back Russia's US r...   \n",
       "\n",
       "                                               Top18  \\\n",
       "0  b'Condoleezza Rice: \"The US would not act to p...   \n",
       "1  b'Riots are still going on in Montreal (Canada...   \n",
       "2  b'Gorbachev accuses U.S. of making a \"serious ...   \n",
       "3             b\"Georgia's DDOS came from US sources\"   \n",
       "4  b'War in the Caucasus is as much the product o...   \n",
       "\n",
       "                                               Top19  \\\n",
       "0  b'This is a busy day:  The European Union has ...   \n",
       "1    b'China to overtake US as largest manufacturer'   \n",
       "2         b'Russia, Georgia, and NATO: Cold War Two'   \n",
       "3  b'Russian convoy heads into Georgia, violating...   \n",
       "4  b'\"Non-media\" photos of South Ossetia/Georgia ...   \n",
       "\n",
       "                                               Top20  \\\n",
       "0  b\"Georgia will withdraw 1,000 soldiers from Ir...   \n",
       "1                     b'War in South Ossetia [PICS]'   \n",
       "2  b'Remember that adorable 62-year-old who led y...   \n",
       "3  b'Israeli defence minister: US against strike ...   \n",
       "4  b'Georgian TV reporter shot by Russian sniper ...   \n",
       "\n",
       "                                               Top21  \\\n",
       "0  b'Why the Pentagon Thinks Attacking Iran is a ...   \n",
       "1  b'Israeli Physicians Group Condemns State Tort...   \n",
       "2          b'War in Georgia: The Israeli connection'   \n",
       "3                     b'Gorbachev: We Had No Choice'   \n",
       "4  b'Saudi Arabia: Mother moves to block child ma...   \n",
       "\n",
       "                                               Top22  \\\n",
       "0  b'Caucasus in crisis: Georgia invades South Os...   \n",
       "1  b' Russia has just beaten the United States ov...   \n",
       "2  b'All signs point to the US encouraging Georgi...   \n",
       "3  b'Witness: Russian forces head towards Tbilisi...   \n",
       "4   b'Taliban wages war on humanitarian aid workers'   \n",
       "\n",
       "                                               Top23  \\\n",
       "0  b'Indian shoe manufactory  - And again in a se...   \n",
       "1  b'Perhaps *the* question about the Georgia - R...   \n",
       "2  b'Christopher King argues that the US and NATO...   \n",
       "3  b' Quarter of Russians blame U.S. for conflict...   \n",
       "4  b'Russia: World  \"can forget about\" Georgia\\'s...   \n",
       "\n",
       "                                               Top24  \\\n",
       "0  b'Visitors Suffering from Mental Illnesses Ban...   \n",
       "1                 b'Russia is so much better at war'   \n",
       "2                        b'America: The New Mexico?'   \n",
       "3  b'Georgian president  says US military will ta...   \n",
       "4  b'Darfur rebels accuse Sudan of mounting major...   \n",
       "\n",
       "                                               Top25  \\\n",
       "0           b\"No Help for Mexico's Kidnapping Surge\"   \n",
       "1  b\"So this is what it's come to: trading sex fo...   \n",
       "2  b\"BBC NEWS | Asia-Pacific | Extinction 'by man...   \n",
       "3  b'2006: Nobel laureate Aleksander Solzhenitsyn...   \n",
       "4  b'Philippines : Peace Advocate say Muslims nee...   \n",
       "\n",
       "                                          Combined25  \n",
       "0  [ 'b\"Georgia \\'downs two Russian warplanes\\' a...  \n",
       "1  [ \"b'Why wont America and Nato help us? If the...  \n",
       "2  [ \"b'Remember that adorable 9-year-old who san...  \n",
       "3  [\"b' U.S. refuses Israel weapons to attack Ira...  \n",
       "4  [\"b'All the experts admit that we should legal...  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data import & Create combined for all top 25 news\n",
    "df = pd.read_csv('/Users/ChienMingHuang/Desktop/Rutgers MIT Course/Fall 2017/Introduction to Data Science/IDSproject/input/Combined_News_DJIA.csv')\n",
    "df['Combined25']= df.iloc[:,2:27].apply(lambda row: ''.join(str(row.values)), axis=1)\n",
    "df.head()\n",
    "# Label variable: 1 if the DJIA stayed the same or rose on that date\n",
    "#                 0 if the DJIA decreased on that date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Combined25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[ 'b\"Georgia \\'downs two Russian warplanes\\' a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[ \"b'Why wont America and Nato help us? If the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[ \"b'Remember that adorable 9-year-old who san...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[\"b' U.S. refuses Israel weapons to attack Ira...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[\"b'All the experts admit that we should legal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                         Combined25\n",
       "0      0  [ 'b\"Georgia \\'downs two Russian warplanes\\' a...\n",
       "1      1  [ \"b'Why wont America and Nato help us? If the...\n",
       "2      0  [ \"b'Remember that adorable 9-year-old who san...\n",
       "3      0  [\"b' U.S. refuses Israel weapons to attack Ira...\n",
       "4      1  [\"b'All the experts admit that we should legal..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train data (2008-08-08 to 2014-12-31)\n",
    "train = df.loc[(pd.to_datetime(df[\"Date\"]) <= date(2014,12,31)),['Label','Combined25']]\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Combined25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1611</th>\n",
       "      <td>1</td>\n",
       "      <td>[ 'Most cases of cancer are the result of shee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1612</th>\n",
       "      <td>0</td>\n",
       "      <td>[ 'Moscow-&amp;gt;Beijing high speed train will re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613</th>\n",
       "      <td>0</td>\n",
       "      <td>['US oil falls below $50 a barrel'\\n \"Toyota g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1614</th>\n",
       "      <td>1</td>\n",
       "      <td>[\"'Shots fired' at French magazine HQ\"\\n '90% ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615</th>\n",
       "      <td>1</td>\n",
       "      <td>[ 'New Charlie Hebdo issue to come out next we...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label                                         Combined25\n",
       "1611      1  [ 'Most cases of cancer are the result of shee...\n",
       "1612      0  [ 'Moscow-&gt;Beijing high speed train will re...\n",
       "1613      0  ['US oil falls below $50 a barrel'\\n \"Toyota g...\n",
       "1614      1  [\"'Shots fired' at French magazine HQ\"\\n '90% ...\n",
       "1615      1  [ 'New Charlie Hebdo issue to come out next we..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test data (2015-01-02 to 2016-07-01)\n",
    "test = df.loc[(pd.to_datetime(df[\"Date\"]) > date(2014,12,31)),['Label','Combined25']]\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC Curves Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ROC Curves metric\n",
    "'''\n",
    "    Plot ROC curves for the multiclass problem\n",
    "    based on http://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html\n",
    "'''\n",
    "def ROCCurves (Actual, Predicted):\n",
    "    \n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    n_classes = 2\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc= dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(Actual.values, Predicted)\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(Actual.ravel(), Predicted.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "    ##############################################################################\n",
    "    # Plot ROC curves for the multiclass problem\n",
    "\n",
    "    # Compute macro-average ROC curve and ROC area\n",
    "\n",
    "    # First aggregate all False Positive Rates\n",
    "\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "    # Interpolate all ROC curves at this points (include FPR, TPR)\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(n_classes):\n",
    "        mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "    # Average it and compute AUC\n",
    "    mean_tpr /= n_classes\n",
    "\n",
    "    fpr[\"macro\"] = all_fpr\n",
    "    tpr[\"macro\"] = mean_tpr\n",
    "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "    # Plot all ROC curves\n",
    "    plt.figure()\n",
    "    plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label = 'micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         linewidth=2)\n",
    "\n",
    "    plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label = 'macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         linewidth=2)\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        plt.plot(fpr[i], tpr[i], label = 'ROC curve of class {0} (area = {1:0.2f})'\n",
    "                                   ''.format(i, roc_auc[i]))\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend(loc = \"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# List to keep different methods scores to compare\n",
    "ScoreSummaryByMethod = []\n",
    "\n",
    "# Evaluation Model build for analyzing model performance\n",
    "'''\n",
    "    Prints and plots\n",
    "    - classification report\n",
    "    - confusion matrix\n",
    "    - ROC-AUC\n",
    "'''\n",
    "def Evaluation (Method,Comment,Actual, Predicted):\n",
    "\n",
    "    print (Method)\n",
    "    print (Comment)\n",
    "    print (classification_report(Actual,Predicted))\n",
    "    print ('Confussion matrix:\\n', confusion_matrix(Actual,Predicted))\n",
    "    ROC_AUC = roc_auc_score(Actual,Predicted)\n",
    "    print ('ROC-AUC: ' + str(ROC_AUC))\n",
    "    \n",
    "    Precision = precision_score(Actual,Predicted)\n",
    "    Accuracy = accuracy_score(Actual,Predicted)\n",
    "    Recall = recall_score(Actual,Predicted)\n",
    "    F1 = f1_score(Actual,Predicted)\n",
    "    ScoreSummaryByMethod.append([Method,Comment,ROC_AUC,Precision,Accuracy,Recall,F1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Text preprocessing:\n",
    "'''\n",
    "1. Tokenizes\n",
    "2. Removes stopwords and coverts headlines to lowercase letters\n",
    "3. Stems\n",
    "4. Returns a list of the cleaned text\n",
    "'''\n",
    "\n",
    "def text_process(text):\n",
    "    if pd.isnull(text):\n",
    "        return []\n",
    "    \n",
    "    # Tokenizes with RegexpTokenizer\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    text_processed=tokenizer.tokenize(text)\n",
    "    \n",
    "    # Removes any stopwords such as , . ; \n",
    "    # Coverts headlines to lowercase letters\n",
    "    text_processed = [word.lower() for word in text_processed if word.lower() not in stopwords.words('english')]\n",
    "    \n",
    "    # Stems\n",
    "    porter_stemmer = PorterStemmer()\n",
    "    \n",
    "    text_processed = [porter_stemmer.stem(word) for word in text_processed]\n",
    "    \n",
    "    try:\n",
    "        text_processed.remove('b')\n",
    "    except: \n",
    "        pass\n",
    "    \n",
    "    # Returns a list of the cleaned text\n",
    "    return text_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words (N-gram Model) & TF-IDF Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag of Words (N-gram Model) <br>\n",
    "An n-gram is a contiguous sequence of n items from a given sequence of text or speech. We use the n-gram to divide the text into different size of words. Then we will use the TF-IDF to calculate the weight of the words.\n",
    "\n",
    "For example, the text \"This is an apple\".\n",
    "\n",
    "When n-gram = 1, the text will be divided into: \"This\", \"is\", \"an\", \"apple\"\n",
    "\n",
    "When n-gram = 2, the text will be divided into: \"This is\", \"is an\", \"an apple\"\n",
    "\n",
    "When n-gram = 3, the text will be divided into: \"This is an\", \"is an apple\"\n",
    "\n",
    "ngram_range:(1,1) is n-gram =1;(1,2) is ngram =1 and ngram =2; (1,3) is ngram values from 1 to 3. <br>\n",
    "Then we will use the TF-IDF to calculate the weight of the words.<br><br>\n",
    "\n",
    "TF-IDF <br>\n",
    "TF-IDF, short for term frequency–inverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus.It is often used as a weighting factor in searches of information retrieval, text mining, and user modeling.\n",
    "\n",
    "1) Term frequency:\n",
    "\n",
    "$TF_{i,j}$  = $\\frac{n_{i,j}}{\\sum_{k}n_{k,j}}$\n",
    "\n",
    "$n_{ij}$ is the number of occurrences of the word in the file $d_j$. And the denominator is the number of occurrences in the file $d_j$ All the words in the number of appearances <br>\n",
    "\n",
    "2) Inverse document frequency:\n",
    "\n",
    "$IDF_i$ = $\\log{\\frac{|D|}{|j:t_i \\in d_j|}}$\n",
    "\n",
    "| D |: The total number of files in the corpus\n",
    "\n",
    "$|j:t_i \\in d_j|$ is the number of $t_i$ in the files <br>\n",
    "\n",
    "3) $TFIDF_{ij}$ = $TF_{i,j}\\times IDF_i$ <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combine Top 3, Top 10 headlines\n",
    "df['Combined3']= df.iloc[:,2:4].apply(lambda row: ''.join(str(row.values)), axis=1)\n",
    "df['Combined10']= df.iloc[:,2:11].apply(lambda row: ''.join(str(row.values)), axis=1)\n",
    "\n",
    "# Create 1 day shift, 2 days shift, 3 days shift\n",
    "df[\"d1\"] = df[\"Label\"].shift(-1)\n",
    "df[\"d1\"].drop(df.index[len(df)-1], inplace=True)\n",
    "df[\"d2\"] = df[\"Label\"].shift(-2)\n",
    "df[\"d2\"].drop(df.index[len(df)-2], inplace=True)\n",
    "df[\"d3\"] = df[\"Label\"].shift(-3)\n",
    "df[\"d3\"].drop(df.index[len(df)-3], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>d1</th>\n",
       "      <th>d2</th>\n",
       "      <th>d3</th>\n",
       "      <th>Combined3</th>\n",
       "      <th>Combined10</th>\n",
       "      <th>Combined25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[ 'b\"Georgia \\'downs two Russian warplanes\\' a...</td>\n",
       "      <td>[ 'b\"Georgia \\'downs two Russian warplanes\\' a...</td>\n",
       "      <td>[ 'b\"Georgia \\'downs two Russian warplanes\\' a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[ \"b'Why wont America and Nato help us? If the...</td>\n",
       "      <td>[ \"b'Why wont America and Nato help us? If the...</td>\n",
       "      <td>[ \"b'Why wont America and Nato help us? If the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[ \"b'Remember that adorable 9-year-old who san...</td>\n",
       "      <td>[ \"b'Remember that adorable 9-year-old who san...</td>\n",
       "      <td>[ \"b'Remember that adorable 9-year-old who san...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[\"b' U.S. refuses Israel weapons to attack Ira...</td>\n",
       "      <td>[\"b' U.S. refuses Israel weapons to attack Ira...</td>\n",
       "      <td>[\"b' U.S. refuses Israel weapons to attack Ira...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[\"b'All the experts admit that we should legal...</td>\n",
       "      <td>[\"b'All the experts admit that we should legal...</td>\n",
       "      <td>[\"b'All the experts admit that we should legal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label   d1   d2   d3                                          Combined3  \\\n",
       "0      0  1.0  0.0  0.0  [ 'b\"Georgia \\'downs two Russian warplanes\\' a...   \n",
       "1      1  0.0  0.0  1.0  [ \"b'Why wont America and Nato help us? If the...   \n",
       "2      0  0.0  1.0  1.0  [ \"b'Remember that adorable 9-year-old who san...   \n",
       "3      0  1.0  1.0  0.0  [\"b' U.S. refuses Israel weapons to attack Ira...   \n",
       "4      1  1.0  0.0  0.0  [\"b'All the experts admit that we should legal...   \n",
       "\n",
       "                                          Combined10  \\\n",
       "0  [ 'b\"Georgia \\'downs two Russian warplanes\\' a...   \n",
       "1  [ \"b'Why wont America and Nato help us? If the...   \n",
       "2  [ \"b'Remember that adorable 9-year-old who san...   \n",
       "3  [\"b' U.S. refuses Israel weapons to attack Ira...   \n",
       "4  [\"b'All the experts admit that we should legal...   \n",
       "\n",
       "                                          Combined25  \n",
       "0  [ 'b\"Georgia \\'downs two Russian warplanes\\' a...  \n",
       "1  [ \"b'Why wont America and Nato help us? If the...  \n",
       "2  [ \"b'Remember that adorable 9-year-old who san...  \n",
       "3  [\"b' U.S. refuses Israel weapons to attack Ira...  \n",
       "4  [\"b'All the experts admit that we should legal...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# New train and test data for later feature selection\n",
    "# Train data (2008-08-08 to 2014-12-31)\n",
    "train = df.loc[(pd.to_datetime(df[\"Date\"]) <= date(2014,12,31)),['Label','d1','d2','d3','Combined3','Combined10','Combined25']]\n",
    "# Train data (2008-08-08 to 2014-12-31)\n",
    "test = df.loc[(pd.to_datetime(df[\"Date\"]) > date(2014,12,31)),['Label','d1','d2','d3','Combined3','Combined10','Combined25']]\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable Runtime Warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logestic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No day shift with top 3, top 10, top 25 news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ngram = (1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "ngram= (1,1), no shift, Top 3 News\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       186\n",
      "          1       0.50      1.00      0.67       189\n",
      "\n",
      "avg / total       0.25      0.50      0.34       375\n",
      "\n",
      "Confussion matrix:\n",
      " [[  0 186]\n",
      " [  0 189]]\n",
      "ROC-AUC: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression with ngram = (1, 1), no shift, Top 3 News\n",
    "lr_1n_t3_0_pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer = text_process,ngram_range = (1, 1))),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', LogisticRegression(C=0.000000001,solver='liblinear',max_iter=200)),\n",
    "])\n",
    "lr_1n_t3_0_pipeline.fit(train['Combined3'],train['Label'])\n",
    "lr_1n_t3_0_prediction = lr_1n_t3_0_pipeline.predict(test['Combined3'])\n",
    "Evaluation ('Linear Regression','ngram= (1,1), no shift, Top 3 News', test[\"Label\"], lr_1n_t3_0_prediction) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 day shift with top 3, top 10, top 25 news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 day shift with top 3, top 10, top 25 news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 day shift with top 3, top 10, top 25 news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No day shift with top 3, top 10, top 25 news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ngram = (1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes\n",
      "ngram= (1,1), no shift, Top 3 News\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.49      0.45      0.47       186\n",
      "          1       0.50      0.54      0.52       189\n",
      "\n",
      "avg / total       0.50      0.50      0.50       375\n",
      "\n",
      "Confussion matrix:\n",
      " [[ 84 102]\n",
      " [ 86 103]]\n",
      "ROC-AUC: 0.4982932241\n"
     ]
    }
   ],
   "source": [
    "# Bernoulli Naive Bayes with ngram = (1, 1), no shift, Top 3 News\n",
    "bnb_1n_t3_0_pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer = text_process,ngram_range = (1, 1))),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', BernoulliNB(alpha = 0.5, binarize = 0.0)),\n",
    "])\n",
    "bnb_1n_t3_0_pipeline.fit(train['Combined3'],train['Label'])\n",
    "bnb_1n_t3_0_prediction = bnb_1n_t3_0_pipeline.predict(test['Combined3'])\n",
    "Evaluation ('Bernoulli Naive Bayes','ngram= (1,1), no shift, Top 3 News', test[\"Label\"], bnb_1n_t3_0_prediction)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes\n",
      "ngram= (1,1), no shift, Top 10 News\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.47      0.39      0.42       186\n",
      "          1       0.49      0.57      0.53       189\n",
      "\n",
      "avg / total       0.48      0.48      0.48       375\n",
      "\n",
      "Confussion matrix:\n",
      " [[ 72 114]\n",
      " [ 81 108]]\n",
      "ROC-AUC: 0.479262672811\n"
     ]
    }
   ],
   "source": [
    "# Bernoulli Naive Bayes with ngram = (1, 1), no shift, Top 10 News\n",
    "bnb_1n_t10_0_pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer = text_process,ngram_range = (1, 1))),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', BernoulliNB(alpha = 0.5, binarize = 0.0)),\n",
    "])\n",
    "bnb_1n_t10_0_pipeline.fit(train['Combined10'],train['Label'])\n",
    "bnb_1n_t10_0_prediction = bnb_1n_t10_0_pipeline.predict(test['Combined10'])\n",
    "Evaluation ('Bernoulli Naive Bayes','ngram= (1,1), no shift, Top 10 News', test[\"Label\"], bnb_1n_t10_0_prediction) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes\n",
      "ngram= (1,1), no shift, Top 25 News\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.49      0.29      0.36       186\n",
      "          1       0.50      0.70      0.58       189\n",
      "\n",
      "avg / total       0.49      0.50      0.47       375\n",
      "\n",
      "Confussion matrix:\n",
      " [[ 54 132]\n",
      " [ 57 132]]\n",
      "ROC-AUC: 0.494367639529\n"
     ]
    }
   ],
   "source": [
    "# Bernoulli Naive Bayes with ngram = (1, 1), no shift, Top 25 News\n",
    "bnb_1n_t25_0_pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer = text_process,ngram_range = (1, 1))),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', BernoulliNB(alpha = 0.5, binarize = 0.0)),\n",
    "])\n",
    "bnb_1n_t25_0_pipeline.fit(train['Combined25'],train['Label'])\n",
    "bnb_1n_t25_0_prediction = bnb_1n_t25_0_pipeline.predict(test['Combined25'])\n",
    "Evaluation ('Bernoulli Naive Bayes','ngram= (1,1), no shift, Top 25 News', test[\"Label\"], bnb_1n_t25_0_prediction)         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ngram = (1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes\n",
      "ngram= (1,2), no shift, Top 3 News\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.49      0.45      0.47       186\n",
      "          1       0.50      0.54      0.52       189\n",
      "\n",
      "avg / total       0.50      0.50      0.50       375\n",
      "\n",
      "Confussion matrix:\n",
      " [[ 84 102]\n",
      " [ 86 103]]\n",
      "ROC-AUC: 0.4982932241\n"
     ]
    }
   ],
   "source": [
    "# Bernoulli Naive Bayes with ngram = (1, 2), no shift, Top 3 News\n",
    "bnb_2n_t3_0_pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer = text_process,ngram_range = (1, 2))),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', BernoulliNB(alpha = 0.5, binarize = 0.0)),\n",
    "])\n",
    "bnb_2n_t3_0_pipeline.fit(train['Combined3'],train['Label'])\n",
    "bnb_2n_t3_0_prediction = bnb_2n_t3_0_pipeline.predict(test['Combined3'])\n",
    "Evaluation ('Bernoulli Naive Bayes','ngram= (1,2), no shift, Top 3 News', test[\"Label\"], bnb_2n_t3_0_prediction)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bernoulli Naive Bayes with ngram = (1, 2), no shift, Top 10 News\n",
    "bnb_2n_t10_0_pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer = text_process,ngram_range = (1, 2))),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', BernoulliNB(alpha = 0.5, binarize = 0.0)),\n",
    "])\n",
    "bnb_2n_t10_0_pipeline.fit(train['Combined10'],train['Label'])\n",
    "bnb_2n_t10_0_prediction = bnb_2n_t10_0_pipeline.predict(test['Combined10'])\n",
    "Evaluation ('Bernoulli Naive Bayes','ngram= (1,2), no shift, Top 10 News', test[\"Label\"], bnb_2n_t10_0_prediction)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bernoulli Naive Bayes with ngram = (1, 2), no shift, Top 25 News\n",
    "bnb_2n_t25_0_pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer = text_process,ngram_range = (1, 2))),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', BernoulliNB(alpha = 0.5, binarize = 0.0)),\n",
    "])\n",
    "bnb_2n_t25_0_pipeline.fit(train['Combined25'],train['Label'])\n",
    "bnb_2n_t25_0_prediction = bnb_2n_t25_0_pipeline.predict(test['Combined25'])\n",
    "Evaluation ('Bernoulli Naive Bayes','ngram= (1,2), no shift, Top 25 News', test[\"Label\"], bnb_2n_t25_0_prediction)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ngram = (1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes\n",
      "ngram= (1,3), no shift, Top 3 News\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.49      0.45      0.47       186\n",
      "          1       0.50      0.54      0.52       189\n",
      "\n",
      "avg / total       0.50      0.50      0.50       375\n",
      "\n",
      "Confussion matrix:\n",
      " [[ 84 102]\n",
      " [ 86 103]]\n",
      "ROC-AUC: 0.4982932241\n"
     ]
    }
   ],
   "source": [
    "# Bernoulli Naive Bayes with ngram = (1, 3), no shift, Top 3 News\n",
    "bnb_3n_t3_0_pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer = text_process,ngram_range = (1, 3))),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', BernoulliNB(alpha = 0.5, binarize = 0.0)),\n",
    "])\n",
    "bnb_3n_t3_0_pipeline.fit(train['Combined3'],train['Label'])\n",
    "bnb_3n_t3_0_prediction = bnb_3n_t3_0_pipeline.predict(test['Combined3'])\n",
    "Evaluation ('Bernoulli Naive Bayes','ngram= (1,3), no shift, Top 3 News', test[\"Label\"], bnb_3n_t3_0_prediction)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes\n",
      "ngram= (1,3), no shift, Top 10 News\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.47      0.39      0.42       186\n",
      "          1       0.49      0.57      0.53       189\n",
      "\n",
      "avg / total       0.48      0.48      0.48       375\n",
      "\n",
      "Confussion matrix:\n",
      " [[ 72 114]\n",
      " [ 81 108]]\n",
      "ROC-AUC: 0.479262672811\n"
     ]
    }
   ],
   "source": [
    "# Bernoulli Naive Bayes with ngram = (1, 3), no shift, Top 10 News\n",
    "bnb_3n_t10_0_pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer = text_process,ngram_range = (1, 3))),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', BernoulliNB(alpha = 0.5, binarize = 0.0)),\n",
    "])\n",
    "bnb_3n_t10_0_pipeline.fit(train['Combined10'],train['Label'])\n",
    "bnb_3n_t10_0_prediction = bnb_3n_t10_0_pipeline.predict(test['Combined10'])\n",
    "Evaluation ('Bernoulli Naive Bayes','ngram= (1,3), no shift, Top 10 News', test[\"Label\"], bnb_3n_t10_0_prediction)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes\n",
      "ngram= (1,3), no shift, Top 25 News\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.49      0.29      0.36       186\n",
      "          1       0.50      0.70      0.58       189\n",
      "\n",
      "avg / total       0.49      0.50      0.47       375\n",
      "\n",
      "Confussion matrix:\n",
      " [[ 54 132]\n",
      " [ 57 132]]\n",
      "ROC-AUC: 0.494367639529\n"
     ]
    }
   ],
   "source": [
    "# Bernoulli Naive Bayes with ngram = (1, 3), no shift, Top 25 News\n",
    "bnb_3n_t25_0_pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer = text_process,ngram_range = (1, 3))),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', BernoulliNB(alpha = 0.5, binarize = 0.0)),\n",
    "])\n",
    "bnb_3n_t25_0_pipeline.fit(train['Combined25'],train['Label'])\n",
    "bnb_3n_t25_0_prediction = bnb_3n_t25_0_pipeline.predict(test['Combined25'])\n",
    "Evaluation ('Bernoulli Naive Bayes','ngram= (1,3), no shift, Top 25 News', test[\"Label\"], bnb_3n_t25_0_prediction)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 day shift with top 3, top 10, top 25 news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ngram = (1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot use a string pattern on a bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-019e4212af72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m ])\n\u001b[1;32m      7\u001b[0m \u001b[0mbnb_1n_t3_1_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Combined3'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'd1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mbnb_1n_t3_1_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbnb_1n_t3_1_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'd1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mEvaluation\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Bernoulli Naive Bayes'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ngram= (1,1), 1 day shift, Top 3 News'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"d1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbnb_1n_t3_1_prediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ChienMingHuang/anaconda/lib/python3.6/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ChienMingHuang/anaconda/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ChienMingHuang/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, raw_documents)\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m         \u001b[0;31m# use the same matrix-building strategy as fit_transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    894\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ChienMingHuang/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-3665aa3c67bb>\u001b[0m in \u001b[0;36mtext_process\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Tokenizes with RegexpTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRegexpTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\w+'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mtext_processed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Removes any stopwords such as , . ;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ChienMingHuang/anaconda/lib/python3.6/site-packages/nltk/tokenize/regexp.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;31m# If our regexp matches tokens, use re.findall:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_regexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mspan_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot use a string pattern on a bytes-like object"
     ]
    }
   ],
   "source": [
    "# Bernoulli Naive Bayes with ngram = (1, 1), 1 day shift, Top 3 News\n",
    "bnb_1n_t3_1_pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer = text_process,ngram_range = (1, 1))),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', BernoulliNB(alpha = 0.5, binarize = 0.0)),\n",
    "])\n",
    "bnb_1n_t3_1_pipeline.fit(train['Combined3'],train['d1'])\n",
    "bnb_1n_t3_1_prediction = bnb_1n_t3_1_pipeline.predict(test['d1'])\n",
    "Evaluation ('Bernoulli Naive Bayes','ngram= (1,1), 1 day shift, Top 3 News', test[\"d1\"], bnb_1n_t3_1_prediction)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Bernoulli Naive Bayes with ngram = (1, 1), no shift, Top 10 News\n",
    "bnb_1n_t10_1_pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer = text_process,ngram_range = (1, 1))),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', BernoulliNB(alpha = 0.5, binarize = 0.0)),\n",
    "])\n",
    "bnb_1n_t10_1_pipeline.fit(train['Combined10'],train['Label'])\n",
    "bnb_1n_t10_1_prediction = bnb_1n_t10_1_pipeline.predict(test['Combined10'])\n",
    "Evaluation ('Bernoulli Naive Bayes','ngram= (1,1), no shift, Top 10 News', test[\"Label\"], bnb_1n_t10_1_prediction) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Bernoulli Naive Bayes with ngram = (1, 1), no shift, Top 25 News\n",
    "bnb_1n_t25_1_pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer = text_process,ngram_range = (1, 1))),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', BernoulliNB(alpha = 0.5, binarize = 0.0)),\n",
    "])\n",
    "bnb_1n_t25_1_pipeline.fit(train['Combined25'],train['Label'])\n",
    "bnb_1n_t25_1_prediction = bnb_1n_t25_1_pipeline.predict(test['Combined25'])\n",
    "Evaluation ('Bernoulli Naive Bayes','ngram= (1,1), no shift, Top 25 News', test[\"Label\"], bnb_1n_t25_1_prediction)         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ngram = (1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ngram = (1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2 day shift with top 3, top 10, top 25 news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ngram = (1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes\n",
      "ngram= (1,1), no shift, Top 3 News\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.49      0.45      0.47       186\n",
      "          1       0.50      0.54      0.52       189\n",
      "\n",
      "avg / total       0.50      0.50      0.50       375\n",
      "\n",
      "Confussion matrix:\n",
      " [[ 84 102]\n",
      " [ 86 103]]\n",
      "ROC-AUC: 0.4982932241\n"
     ]
    }
   ],
   "source": [
    "# Bernoulli Naive Bayes with ngram = (1, 1), no shift, Top 3 News\n",
    "bnb_1n_t3_2_pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer = text_process,ngram_range = (1, 1))),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', BernoulliNB(alpha = 0.5, binarize = 0.0)),\n",
    "])\n",
    "bnb_1n_t3_2_pipeline.fit(train['Combined3'],train['Label'])\n",
    "bnb_1n_t3_2_prediction = bnb_1n_t3_2_pipeline.predict(test['Combined3'])\n",
    "Evaluation ('Bernoulli Naive Bayes','ngram= (1,1), no shift, Top 3 News', test[\"Label\"], bnb_1n_t3_2_prediction)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes\n",
      "ngram= (1,1), no shift, Top 10 News\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.47      0.39      0.42       186\n",
      "          1       0.49      0.57      0.53       189\n",
      "\n",
      "avg / total       0.48      0.48      0.48       375\n",
      "\n",
      "Confussion matrix:\n",
      " [[ 72 114]\n",
      " [ 81 108]]\n",
      "ROC-AUC: 0.479262672811\n"
     ]
    }
   ],
   "source": [
    "# Bernoulli Naive Bayes with ngram = (1, 1), no shift, Top 10 News\n",
    "bnb_1n_t10_2_pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer = text_process,ngram_range = (1, 1))),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', BernoulliNB(alpha = 0.5, binarize = 0.0)),\n",
    "])\n",
    "bnb_1n_t10_2_pipeline.fit(train['Combined10'],train['Label'])\n",
    "bnb_1n_t10_2_prediction = bnb_1n_t10_2_pipeline.predict(test['Combined10'])\n",
    "Evaluation ('Bernoulli Naive Bayes','ngram= (1,1), no shift, Top 10 News', test[\"Label\"], bnb_1n_t10_2_prediction) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes\n",
      "ngram= (1,1), no shift, Top 25 News\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.49      0.29      0.36       186\n",
      "          1       0.50      0.70      0.58       189\n",
      "\n",
      "avg / total       0.49      0.50      0.47       375\n",
      "\n",
      "Confussion matrix:\n",
      " [[ 54 132]\n",
      " [ 57 132]]\n",
      "ROC-AUC: 0.494367639529\n"
     ]
    }
   ],
   "source": [
    "# Bernoulli Naive Bayes with ngram = (1, 1), no shift, Top 25 News\n",
    "bnb_1n_t25_2_pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer = text_process,ngram_range = (1, 1))),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', BernoulliNB(alpha = 0.5, binarize = 0.0)),\n",
    "])\n",
    "bnb_1n_t25_2_pipeline.fit(train['Combined25'],train['Label'])\n",
    "bnb_1n_t25_2_prediction = bnb_1n_t25_2_pipeline.predict(test['Combined25'])\n",
    "Evaluation ('Bernoulli Naive Bayes','ngram= (1,1), no shift, Top 25 News', test[\"Label\"], bnb_1n_t25_2_prediction)         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ngram = (1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ngram = (1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 day shift with top 3, top 10, top 25 news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ngram = (1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes\n",
      "ngram= (1,1), no shift, Top 3 News\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.49      0.45      0.47       186\n",
      "          1       0.50      0.54      0.52       189\n",
      "\n",
      "avg / total       0.50      0.50      0.50       375\n",
      "\n",
      "Confussion matrix:\n",
      " [[ 84 102]\n",
      " [ 86 103]]\n",
      "ROC-AUC: 0.4982932241\n"
     ]
    }
   ],
   "source": [
    "# Bernoulli Naive Bayes with ngram = (1, 1), no shift, Top 3 News\n",
    "bnb_1n_t3_3_pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer = text_process,ngram_range = (1, 1))),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', BernoulliNB(alpha = 0.5, binarize = 0.0)),\n",
    "])\n",
    "bnb_1n_t3_3_pipeline.fit(train['Combined3'],train['Label'])\n",
    "bnb_1n_t3_3_prediction = bnb_1n_t3_3_pipeline.predict(test['Combined3'])\n",
    "Evaluation ('Bernoulli Naive Bayes','ngram= (1,1), no shift, Top 3 News', test[\"Label\"], bnb_1n_t3_3_prediction)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes\n",
      "ngram= (1,1), no shift, Top 10 News\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.47      0.39      0.42       186\n",
      "          1       0.49      0.57      0.53       189\n",
      "\n",
      "avg / total       0.48      0.48      0.48       375\n",
      "\n",
      "Confussion matrix:\n",
      " [[ 72 114]\n",
      " [ 81 108]]\n",
      "ROC-AUC: 0.479262672811\n"
     ]
    }
   ],
   "source": [
    "# Bernoulli Naive Bayes with ngram = (1, 1), no shift, Top 10 News\n",
    "bnb_1n_t10_3_pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer = text_process,ngram_range = (1, 1))),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', BernoulliNB(alpha = 0.5, binarize = 0.0)),\n",
    "])\n",
    "bnb_1n_t10_3_pipeline.fit(train['Combined10'],train['Label'])\n",
    "bnb_1n_t10_3_prediction = bnb_1n_t10_3_pipeline.predict(test['Combined10'])\n",
    "Evaluation ('Bernoulli Naive Bayes','ngram= (1,1), no shift, Top 10 News', test[\"Label\"], bnb_1n_t10_3_prediction) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes\n",
      "ngram= (1,1), no shift, Top 25 News\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.49      0.29      0.36       186\n",
      "          1       0.50      0.70      0.58       189\n",
      "\n",
      "avg / total       0.49      0.50      0.47       375\n",
      "\n",
      "Confussion matrix:\n",
      " [[ 54 132]\n",
      " [ 57 132]]\n",
      "ROC-AUC: 0.494367639529\n"
     ]
    }
   ],
   "source": [
    "# Bernoulli Naive Bayes with ngram = (1, 1), no shift, Top 25 News\n",
    "bnb_1n_t25_3_pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer = text_process,ngram_range = (1, 1))),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', BernoulliNB(alpha = 0.5, binarize = 0.0)),\n",
    "])\n",
    "bnb_1n_t25_3_pipeline.fit(train['Combined25'],train['Label'])\n",
    "bnb_1n_t25_3_prediction = bnb_1n_t25_3_pipeline.predict(test['Combined25'])\n",
    "Evaluation ('Bernoulli Naive Bayes','ngram= (1,1), no shift, Top 25 News', test[\"Label\"], bnb_1n_t25_3_prediction)         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ngram = (1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ngram = (1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## No day shift with top 3, top 10, top 25 news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ngram = (1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ngram = (1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ngram = (1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 day shift with top 3, top 10, top 25 news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ngram = (1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ngram = (1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ngram = (1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 day shift with top 3, top 10, top 25 news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ngram = (1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ngram = (1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ngram = (1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 day shift with top 3, top 10, top 25 news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ngram = (1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ngram = (1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ngram = (1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score Summary by Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Show the top 20 model performance sorted on AUC performance\n",
    "df_ScoreSummaryByMethod=DataFrame(ScoreSummaryByMethod,columns=['Method','Comment','ROC_AUC','Precision','Accuracy','Recall','F1'])\n",
    "df_ScoreSummaryByMethod.sort_values(['ROC_AUC'],ascending=False,inplace=True)\n",
    "df_ScoreSummaryByMethod.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
